---
title: '箸休め - AI についての雑学'
---

## AI についての雑学

ここで、少し箸休めに AI の雑学について解説しましょう。

少し講習に飽きてきた方や、ちょっとプロンプトがうまくいかないなあという方は聞いていただけると良いかと思います！

<br />

## AI の歴史

AI はここ数年でとてつもなく話題になってますよね。では、いつごろ AI という存在が出てきたか知っていますか？

なんと、AI という言葉は、1956年にアメリカのダートマス大学で開催された「ダートマス会議」で、ジョン・マッカーシーによって初めて提唱されました！

この会議は、人工知能研究の幕開けを告げるものとして知られています。

<br />

## ピンクの象問題

突然ですがみなさん、**「ピンクの象を考えないでください」**。

どうでしょう？\
今、かえってピンクの象を想像してしまったのではないでしょうか。

これはピンクの像現象といい、人間が否定形を処理する際に、まずその対象を思い浮かべてから否定するという特性があるためです。

実は AI においても同様の課題が存在します。\
AIは学習データに基づいてパターンを認識し、情報を生成しますが、「〜しない」といった否定的な指示を正確に理解し、その概念を完全に排除して情報を生成することは非常に難しい場合があります。\
この問題は、AIが特定の情報を「忘れる」ことや「無視する」ことの難しさを示す一例として挙げられますね！

そのため、プロンプトがうまく動作しないと感じたら、ぜひ、「しないでください」ではなく「してください」といったプロンプトに変えてみると良いと思います！

<br />

## なぜAIは嘘をつくのか？（ハルシネーション）

AIが「嘘」をつくことってよくありませんか？

AIが事実に基づかない、あるいは誤った情報を生成してしまう現象を「ハルシネーション（幻覚）」と呼びます。これはAIが「嘘をついている」わけではなく、以下のような原因が考えられます。

- **学習データの偏りや不足**: AIは学習したデータに基づいて推論を行いますが、データに偏りがあったり、特定の情報が不足している場合、不正確な情報を生成することがあります。

- **推論の誤り**: AIの内部的な推論プロセスにおいて、複雑な状況や曖昧な情報に対して誤った解釈をしてしまうことがあります。

- **もっともらしい情報の生成**: AIは、与えられたプロンプトに対して最も「もっともらしい」回答を生成しようとします。その結果、事実とは異なるのに文脈上は自然に見える情報を生成してしまうことがあります。

ハルシネーションへの対策としては、AI が生成した情報のファクトチェック（事実確認）を行うことが非常に重要です！
